# -*- coding: utf-8 -*-
import warnings
# å±è”½çƒ¦äººçš„ç¬¬ä¸‰æ–¹åº“è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module='py_mini_racer')
warnings.filterwarnings("ignore", category=UserWarning, module='pkg_resources')
warnings.filterwarnings("ignore", category=DeprecationWarning, module='pkg_resources')

import efinance as ef
import akshare as ak
import pandas as pd
import os
import time
import datetime
from tqdm import tqdm 
import config

class MarketUpdater:
    def __init__(self):
        self.repo_dir = config.DATA_REPO
        self.snapshot_file = os.path.join(self.repo_dir, 'market_snapshot_full.csv')
        self.daily_dir = config.DIR_DAILY
        
        # é…ç½®ï¼šæ¯æ‰¹æ¬¡å¤„ç†æ•°é‡å’Œä¼‘æ¯æ—¶é—´ï¼Œé˜²å°IP
        self.BATCH_SIZE = 50 
        self.SLEEP_TIME = 1.5 

    def update_market_snapshot(self):
        """
        ä»»åŠ¡1ï¼šæ›´æ–°å…¨å¸‚åœºå¿«ç…§ï¼ˆç”¨äºé€‰è‚¡å™¨ï¼‰
        """
        print("ğŸ”„ [ä»»åŠ¡1] å¼€å§‹æ›´æ–°å…¨å¸‚åœºå¿«ç…§...")
        try:
            # 1. å°è¯• efinance è·å–å…¨å¸‚åœº (é€Ÿåº¦å¿«)
            df = ef.stock.get_realtime_quotes('æ²ªæ·±Aè‚¡')
            if df is not None and not df.empty:
                rename_map = {
                    'ä»£ç ': 'code', 'åç§°': 'name', 'æœ€æ–°ä»·': 'price', 
                    'æ¶¨è·Œå¹…': 'pct_chg', 'åŠ¨æ€å¸‚ç›ˆç‡': 'pe', 'æ€»å¸‚å€¼': 'market_cap', 
                    'æ‰€å¤„è¡Œä¸š': 'industry', 'æˆäº¤é‡': 'volume', 'æ¢æ‰‹ç‡': 'turnover'
                }
                df = df.rename(columns=rename_map)
                
                cols = ['code', 'name', 'price', 'pct_chg', 'pe', 'market_cap', 'industry', 'turnover']
                for c in cols:
                    if c not in df.columns: df[c] = 0
                
                df['update_time'] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                df.to_csv(self.snapshot_file, index=False)
                print(f"âœ… å¿«ç…§æ›´æ–°æˆåŠŸï¼å…± {len(df)} åªè‚¡ç¥¨ï¼Œå·²å­˜å…¥ data_repo/market_snapshot_full.csv")
                return df
                
        except Exception as e:
            print(f"âš ï¸ efinance æ¥å£æ³¢åŠ¨: {e}")
            print("ğŸ”„ æ­£åœ¨å°è¯• AkShare å¤‡ç”¨æ¥å£...")

        # å¤‡ç”¨ï¼šAkShare
        try:
            df = ak.stock_zh_a_spot_em()
            if df is not None and not df.empty:
                rename_map = {
                    'ä»£ç ': 'code', 'åç§°': 'name', 'æœ€æ–°ä»·': 'price', 
                    'æ¶¨è·Œå¹…': 'pct_chg', 'å¸‚ç›ˆç‡-åŠ¨æ€': 'pe', 'æ€»å¸‚å€¼': 'market_cap', 
                    'æ¢æ‰‹ç‡': 'turnover'
                }
                df = df.rename(columns=rename_map)
                df['industry'] = 'å…¶ä»–' # AkShare æ­¤æ¥å£ä¸å¸¦è¡Œä¸š
                df['update_time'] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
                # ç¡®ä¿åˆ—å­˜åœ¨
                if 'pe' not in df.columns: df['pe'] = 0
                
                df.to_csv(self.snapshot_file, index=False)
                print(f"âœ… (å¤‡ç”¨æº) å¿«ç…§æ›´æ–°æˆåŠŸï¼å…± {len(df)} åªè‚¡ç¥¨ã€‚")
                return df
        except Exception as e:
            print(f"âŒ æ‰€æœ‰æ¥å£å‡å¤±è´¥: {e}")
            return None

    def update_all_kline_incremental(self, days_back=365):
        """
        ä»»åŠ¡2ï¼šå…¨é‡/å¢é‡æ›´æ–°æ—¥Kçº¿
        """
        print("\nğŸ”„ [ä»»åŠ¡2] å¼€å§‹æ›´æ–°ä¸ªè‚¡Kçº¿æ•°æ® (å¢é‡æ¨¡å¼)...")
        
        if os.path.exists(self.snapshot_file):
            df_market = pd.read_csv(self.snapshot_file, dtype={'code': str})
        else:
            print("âš ï¸ æœªæ‰¾åˆ°å¿«ç…§æ–‡ä»¶ï¼Œæ­£åœ¨å…ˆæ‰§è¡Œä»»åŠ¡1...")
            self.update_market_snapshot()
            if os.path.exists(self.snapshot_file):
                df_market = pd.read_csv(self.snapshot_file, dtype={'code': str})
            else:
                print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚")
                return

        all_codes = df_market['code'].tolist()
        total = len(all_codes)
        print(f"ğŸ¯ ç›®æ ‡ï¼šæ›´æ–° {total} åªè‚¡ç¥¨çš„æ—¥çº¿æ•°æ®")
        print("â˜• è¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        for i in tqdm(range(0, total, self.BATCH_SIZE), desc="è¿›åº¦"):
            batch_codes = all_codes[i : i + self.BATCH_SIZE]
            
            for code in batch_codes:
                self._update_single_stock(code, days_back)
            
            time.sleep(self.SLEEP_TIME)

    def _update_single_stock(self, code, days_back):
        file_path = os.path.join(self.daily_dir, f"{code}_qfq.csv")
        
        try:
            start_date = None
            old_df = pd.DataFrame()
            
            if os.path.exists(file_path):
                try:
                    old_df = pd.read_csv(file_path)
                    if 'timestamps' in old_df.columns and not old_df.empty:
                        last_date = pd.to_datetime(old_df['timestamps']).max()
                        start_date = (last_date + datetime.timedelta(days=1)).strftime("%Y%m%d")
                except: pass
            
            if not start_date:
                start_date = (datetime.datetime.now() - datetime.timedelta(days=days_back)).strftime("%Y%m%d")
            
            end_date = datetime.datetime.now().strftime("%Y%m%d")
            
            if start_date > end_date: return

            df_new = ak.stock_zh_a_hist(symbol=code, period="daily", start_date=start_date, end_date=end_date, adjust="qfq")
            
            if df_new is None or df_new.empty: return

            rename_map = {
                'æ—¥æœŸ': 'timestamps', 'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close', 
                'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æˆäº¤é‡': 'volume', 'æˆäº¤é¢': 'amount'
            }
            df_new = df_new.rename(columns=rename_map)
            df_new = df_new[['timestamps', 'open', 'close', 'high', 'low', 'volume', 'amount']]
            
            if not old_df.empty:
                if 'amount' not in old_df.columns: old_df['amount'] = 0
                df_final = pd.concat([old_df, df_new])
                df_final = df_final.drop_duplicates(subset=['timestamps'], keep='last')
                df_final = df_final.sort_values('timestamps')
            else:
                df_final = df_new
                
            df_final.to_csv(file_path, index=False)
            
        except:
            pass

if __name__ == "__main__":
    print("\n" + "="*40)
    print("ğŸš€ Kronos æ•°æ®ä¸­å¿ƒåå°ç»´æŠ¤ç¨‹åº")
    print("="*40)
    print("1. ä»…æ›´æ–°å…¨å¸‚åœºå¿«ç…§ (é€‰è‚¡å™¨ç”¨, é€Ÿåº¦å¿«)")
    print("2. å…¨é‡æ›´æ–° K çº¿æ•°æ® (åˆ†æå°ç”¨, é€Ÿåº¦æ…¢)")
    print("3. åŒæ—¶æ‰§è¡Œ 1 å’Œ 2")
    
    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ [1/2/3]: ").strip()
    
    updater = MarketUpdater()
    
    if choice == '1':
        updater.update_market_snapshot()
    elif choice == '2':
        updater.update_all_kline_incremental()
    elif choice == '3':
        updater.update_market_snapshot()
        updater.update_all_kline_incremental()
    else:
        print("æ— æ•ˆé€‰é¡¹ï¼Œé€€å‡ºã€‚")